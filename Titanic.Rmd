---
title: "Titanic"
author: "Learning Curve"
date: "10/2/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}
library(ggplot2)
library(stringr)
```

## Titanic

```{r}

train <- read.csv("~/DataScience/data files/train.csv",header = TRUE)
test <- read.csv("~/DataScience/data files/test.csv", header = TRUE)
```

```{r}
head(train)
```

```{r}
head(test)
```


```{r}
# Combine data sets
data.combined <- rbind(train, test)
str(data.combined)
```

```{r}

data.combined$Survived <- as.factor(data.combined$Survived)
data.combined$Pclass <- as.factor(data.combined$Pclass)

```

```{r}
# Take a look at gross survival rates
table(data.combined$Survived)

```

```{r}
# Distribution across classes
table(data.combined$Pclass)

```


### Hypothesis - Rich folks survived at a higer rate
```{r}

train$Pclass <- as.factor(train$Pclass)
ggplot(train, aes(x = Pclass, fill = factor(Survived))) +
  geom_bar(width = 0.5) +
  xlab("Pclass") +
  ylab("Total Count") +
  labs(fill = "Survived") 

```

#### Examine the first few names in the training data set
```{r}

head(as.character(train$Name))
```

```{r}
# How many unique names are there across both train & test?
length(unique(as.character(data.combined$Name)))

```

```{r}
# Two duplicate names, take a closer look
# First, get the duplicate names and store them as a vector
dup.names <- as.character(data.combined[which(duplicated(as.character(data.combined$Name))), "name"])

```

```{r}
# Next, take a look at the records in the combined data set
data.combined[which(data.combined$Name %in% dup.names),]

```

```{r}
# Any correlation with other variables (e.g., sibsp)?
misses <- data.combined[which(str_detect(data.combined$Name, "Miss.")),]
misses[1:5,]

```

```{r}
# Hypothesis - Name titles correlate with age
mrses <- data.combined[which(str_detect(data.combined$Name, "Mrs.")), ]
mrses[1:5,]

```
```{r}
# Check out males to see if pattern continues
males <- data.combined[which(data.combined$Sex == "male"), ]
males[1:5,]

```


 Expand upon the realtionship between `Survived` and `Pclass` by adding the new `Title` variable to the
 data set and then explore a potential 3-dimensional relationship.

Create a utility function to help with title extraction
NOTE - Using the grep function here, but could have used the str_detect function as well.

```{r}
extractTitle <- function(Name) {
  Name <- as.character(Name)
  
  if (length(grep("Miss.", Name)) > 0) {
    return ("Miss.")
  } else if (length(grep("Master.", Name)) > 0) {
    return ("Master.")
  } else if (length(grep("Mrs.", Name)) > 0) {
    return ("Mrs.")
  } else if (length(grep("Mr.", Name)) > 0) {
    return ("Mr.")
  } else {
    return ("Other")
  }
}
```



```{r}

titles <- NULL
for (i in 1:nrow(data.combined)) {
  titles <- c(titles, extractTitle(data.combined[i,"Name"]))
}
data.combined$title <- as.factor(titles)

```



```{r}

ggplot(data.combined[1:891,], aes(x = title, fill = Survived)) +
  geom_bar() +
  facet_wrap(~Pclass) + 
  ggtitle("Pclass") +
  xlab("Title") +
  ylab("Total Count") +
  labs(fill = "Survived")
```
Age and sex seem pretty important as derived from analysis of title, let's take a closer look at the distibutions of age over entire train data set

```{r}

summary(train$Age)

```

Take a look at the survival rates broken out by sex,pclass and age
```{r}

ggplot(train, aes(x = Age, fill = Survived)) +
  facet_wrap(~Sex + Pclass) +
geom_histogram(binwidth = 10) +
  xlab("Age") +
  ylab("Total Count")
```

Validate that "Master." is a good proxy for male children
```{r}

boys <- data.combined[which(data.combined$title == "Master."),]
summary(boys$Age)
```

 We know that "Miss." is more complicated, let's examine further
 
```{r}
misses <- data.combined[which(data.combined$title == "Miss."),]
summary(misses$Age)

```

```{r}
ggplot(misses[misses$Survived != "None",], aes(x = Age, fill = Survived)) +
  facet_wrap(~Pclass) +
  geom_histogram(binwidth = 5) +
  ggtitle("Age for 'Miss.' by Pclass") + 
  xlab("Age") +
  ylab("Total Count")

```
Appears female children may have different survival rate, 
could be a candidate for feature engineering later

```{r}
misses.alone <- misses[which(misses$SibSp == 0 & misses$Parch == 0),]
summary(misses.alone$Age)
length(which(misses.alone$Age <= 14.5))
```

```{r}
# Move on to the sibsp variable, summarize the variable
summary(data.combined$SibSp)


# Can we treat as a factor?
length(unique(data.combined$SibSp))
data.combined$SibSp <- as.factor(data.combined$SibSp)

```

We believe title is predictive. Visualize survival reates by sibsp, pclass, and title
```{r}
ggplot(data.combined[1:891,], aes(x = SibSp, fill = Survived)) +
geom_bar() +
  facet_wrap(~Pclass + title) + 
  ggtitle("Pclass, Title") +
  xlab("SibSp") +
  ylab("Total Count") +
  ylim(0,300)
  labs(fill = "Survived")
```

 Treat the parch vaiable as a factor and visualize

```{r}
data.combined$Parch <- as.factor(data.combined$Parch)
ggplot(data.combined[1:891,], aes(x = Parch, fill = Survived)) +
  geom_bar() +
  facet_wrap(~Pclass + title) + 
  ggtitle("Pclass, Title") +
  xlab("ParCh") +
  ylab("Total Count") +
  ylim(0,30) +
  labs(fill = "Survived")
```

Let's try some feature engineering. What about creating a family size feature?

```{r}
temp.SibSp <- c(train$SibSp, test$SibSp)
temp.Parch <- c(train$Parch, test$Parch)
data.combined$family.size <- as.factor(temp.SibSp + temp.Parch + 1)

```


```{r}
# Visualize it to see if it is predictive
ggplot(data.combined[1:891,], aes(x = family.size, fill = Survived)) +
  geom_bar() +
  facet_wrap(~Pclass + title) + 
  ggtitle("Pclass, Title") +
  xlab("family.size") +
  ylab("Total Count") +
  ylim(0,300) +
  labs(fill = "Survived")
```

Take a look at the ticket variable

```{r}
str(data.combined$Ticket)
```
Based on the huge number of levels ticket really isn't a factor variable it is a string. 

```{r}
data.combined$Ticket <- as.character(data.combined$Ticket)
data.combined$Ticket[1:5]
```
There's no immediately apparent structure in the data, let's see if we can find some.We'll start with taking a look at just the first char for each

```{r}
ticket.first.char <-  substr(data.combined$Ticket, 1, 1)
unique(ticket.first.char)

```

OK, we can make a factor for analysis purposes and visualize
```{r}
data.combined$ticket.first.char <- as.factor(ticket.first.char)
```

Lets plot survival rate for each class of ticket
```{r}
ggplot(data.combined[1:891,], aes(x = ticket.first.char, fill = Survived)) +
  geom_bar() +
  ggtitle("Survivability by ticket.first.char") +
  xlab("ticket.first.char") +
  ylab("Total Count") +
  ylim(0,350) +
  labs(fill = "Survived")


```

Ticket seems like it might be predictive, drill down a bit

```{r}
ggplot(data.combined[1:891,], aes(x = ticket.first.char, fill = Survived)) +
  geom_bar() +
  facet_wrap(~Pclass) + 
  ggtitle("Pclass") +
  xlab("ticket.first.char") +
  ylab("Total Count") +
  ylim(0,300) +
  labs(fill = "Survived")
```


```{r}
ggplot(data.combined[1:891,], aes(x = ticket.first.char, fill = Survived)) +
  geom_bar() +
  facet_wrap(~Pclass+title) + 
  ggtitle("Pclass, Title") +
  xlab("ticket.first.char") +
  ylab("Ticket class") +
  ylim(0,200) +
  labs(fill = "Survived")
```
Next up - the fares Titanic passengers paid

```{r}
summary(data.combined$Fare)
length(unique(data.combined$Fare))

```

```{r}
#Can't make fare a factor, treat as numeric & visualize with histogram
ggplot(data.combined, aes(x = Fare)) +
  geom_histogram(binwidth = 5) +
  ggtitle("Combined Fare Distribution") +
  xlab("Fare") +
  ylab("Total Count") +
  ylim(0,200)

```

```{r}
# Let's check to see if fare has predictive power
ggplot(data.combined[1:891,], aes(x = Fare, fill = Survived)) +
  geom_histogram(binwidth = 5) +
  facet_wrap(~Pclass + title) + 
  ggtitle("Pclass, Title") +
  xlab("fare") +
  ylab("Total Count") +
  ylim(0,50)
  labs(fill = "Survived")

```
```{r}
# Analysis of the cabin variable
str(data.combined$Cabin)

```

```{r}
#Cabin really isn't a factor, make a string and the display first 100
data.combined$Cabin <- as.character(data.combined$Cabin)
data.combined$Cabin[1:5]
```

There are missing cabin values. Replace empty cabins with a "U"
```{r}
data.combined[which(data.combined$Cabin == ""), "Cabin"] <- "U"
data.combined$Cabin[1:10]

```

Take a look at the 1st character of the cabin
```{r}
cabin.first.char <- as.factor(substr(data.combined$Cabin, 1, 1))
str(cabin.first.char)
levels(cabin.first.char)

```

```{r}
 # Add to combined data set and plot 
data.combined$cabin.first.char <- cabin.first.char

# High level plot
ggplot(data.combined[1:891,], aes(x = cabin.first.char, fill = Survived)) +
  geom_bar() +
  ggtitle("Survivability by cabin.first.char") +
  xlab("cabin.first.char") +
  ylab("Total Count") +
  ylim(0,750) +
  labs(fill = "Survived")
```


```{r}
# Could have some predictive power, drill in
ggplot(data.combined[1:891,], aes(x = cabin.first.char, fill = Survived)) +
  geom_bar() +
  facet_wrap(~Pclass) +
  ggtitle("Survivability by cabin.first.char") +
  xlab("Pclass") +
  ylab("Total Count") +
  ylim(0,500) +
  labs(fill = "Survived")
```
```{r}
# Does this feature improve upon pclass + title?
ggplot(data.combined[1:891,], aes(x = cabin.first.char, fill = Survived)) +
  geom_bar() +
  facet_wrap(~Pclass + title) +
  ggtitle("Pclass, Title") +
  xlab("cabin.first.char") +
  ylab("Total Count") +
  ylim(0,500) +
  labs(fill = "Survived")
```

```{r}
# Does survivability depend on where you got onboard the Titanic?
str(data.combined$Embarked)
levels(data.combined$Embarked)


# Plot data for analysis
ggplot(data.combined[1:891,], aes(x = Embarked, fill = Survived)) +
  geom_bar() +
  facet_wrap(~Pclass + title) +
  ggtitle("Pclass, Title") +
  xlab("embarked") +
  ylab("Total Count") +
  ylim(0,300) +
  labs(fill = "Survived")

```

##  Exploratory Modeling


```{r}

library(randomForest)

# Train a Random Forest with the default parameters using pclass & title
rf.train.1 <- data.combined[1:891, c("Pclass", "title")]
rf.label <- as.factor(train$Survived)

set.seed(1234)
rf.1 <- randomForest(x = rf.train.1, y = rf.label, importance = TRUE, ntree = 1000)
rf.1


```

```{r}
varImpPlot(rf.1)
```

```{r}
# Train a Random Forest using pclass, title, & sibsp
rf.train.2 <- data.combined[1:891, c("Pclass", "title", "SibSp")]

set.seed(1234)
rf.2 <- randomForest(x = rf.train.2, y = rf.label, importance = TRUE, ntree = 1000)
rf.2
```

```{r}
varImpPlot(rf.2)
```
Definately title is a very important feature

Lets see with parent with child (parch)
```{r}
# Train a Random Forest using pclass, title, & parch
rf.train.3 <- data.combined[1:891, c("Pclass", "title", "Parch")]

set.seed(1234)
rf.3 <- randomForest(x = rf.train.3, y = rf.label, importance = TRUE, ntree = 1000)
rf.3

```

```{r}
varImpPlot(rf.3)
```

Train a Random Forest using pclass, title, & family.size
```{r}
rf.train.4 <- data.combined[1:891, c("Pclass", "title", "family.size")]

set.seed(1234)
rf.4 <- randomForest(x = rf.train.4, y = rf.label, importance = TRUE, ntree = 1000)
rf.4

```


```{r}
varImpPlot(rf.4)
```


```{r}
#Train a Random Forest using pclass, title, sibsp, & family.size
rf.train.6 <- data.combined[1:891, c("Pclass", "title", "SibSp", "family.size")]

set.seed(1234)
rf.6 <- randomForest(x = rf.train.6, y = rf.label, importance = TRUE, ntree = 1000)
rf.6


```

```{r}
varImpPlot(rf.6)
```

## Cross Validation
 
Before we jump into features engineering we need to establish a methodology
for estimating our error rate on the test set. This is
critical, for without this we are more likely to overfit. Let's start with a 
submission of rf.4 to Kaggle to see if our OOB error estimate is accurate.
 
```{r}
# Subset our test records and features
test.submit.df <- data.combined[892:1309, c("Pclass", "title", "family.size")]

# Make predictions
rf.4.preds <- predict(rf.4, test.submit.df)
table(rf.4.preds)

```
Cross Validation 



Lets use decision tree for the same features

```{r}
library(rpart)
library(rpart.plot)

library(caret)
library(doSNOW)
```
 
```{r}
set.seed(2348)
cv.10.folds <- createMultiFolds(rf.label, k = 10, times = 10)

# Check stratification
table(rf.label)

```
 
```{r}
table(rf.label[cv.10.folds[[33]]])
```

```{r}
# Set up caret's trainControl object per above.
ctrl.1 <- trainControl(method = "repeatedcv", number = 10, repeats = 10,
                       index = cv.10.folds)

```


```{r}
#Set up doSNOW package for multi-core training. This is helpful as we're going
# to be training a lot of trees.

cl <- makeCluster(6, type = "SOCK")
registerDoSNOW(cl)
```


```{r}
#Create utility function
rpart.cv <- function(seed, training, labels, ctrl) {
  cl <- makeCluster(6, type = "SOCK")
  registerDoSNOW(cl)
  
  set.seed(seed)
  # Leverage formula interface for training
  rpart.cv <- train(x = training, y = labels, method = "rpart", tuneLength = 30, 
                    trControl = ctrl)
  
  #Shutdown cluster
  stopCluster(cl)
  
  return (rpart.cv)
}
```

```{r}
#lets try   3-fold CV repeated 10 times. 
set.seed(37596)
cv.3.folds <- createMultiFolds(rf.label, k = 3, times = 10)

ctrl.3 <- trainControl(method = "repeatedcv", number = 3, repeats = 10,
                       index = cv.3.folds)

```



```{r,warning= FALSE}

# Grab features
features <- c("Pclass", "title", "family.size")
rpart.train.1 <- data.combined[1:891, features]

# Run CV and check out results
rpart.1.cv.1 <- rpart.cv(94622, rpart.train.1, rf.label, ctrl.3)
rpart.1.cv.1
```
```{r}
# Plot
prp(rpart.1.cv.1$finalModel, type = 0, extra = 1, under = TRUE)

```


### The plot bring out some interesting lines of investigation. Namely:
-  Titles of "Mr." and "Other" are predicted to perish at an overall accuracy rate of 83.2 %.
-  Titles of "Master.", "Miss.", & "Mrs." in 1st & 2nd class
   are predicted to survive at an overall accuracy rate of 94.9%.
-  Titles of "Master.", "Miss.", & "Mrs." in 3rd class with family sizes equal to 5, 6, 8, & 11 are predicted to perish with 100% accuracy.
-  Titles of "Master.", "Miss.", & "Mrs." in 3rd class with  family sizes not equal to 5, 6, 8, or 11 are predicted to survive with 59.6% accuracy.


```{r}
#Both rpart and rf confirm that title is important, let's investigate further
table(data.combined$title)

```

```{r}
name.splits <- str_split(data.combined$Name, ",")
name.splits[1]
last.names <- sapply(name.splits, "[", 1)
last.names[1:10]
```

```{r}
# Add last names to dataframe in case we find it useful later
data.combined$last.name <- last.names

# Now for titles
name.splits <- str_split(sapply(name.splits, "[", 2), " ")
titles <- sapply(name.splits, "[", 2)
unique(titles)
```

```{r}
# What's up with a title of 'the'?
data.combined[which(titles == "the"),]

# Re-map titles to be more exact
titles[titles %in% c("Dona.", "the")] <- "Lady."
titles[titles %in% c("Ms.", "Mlle.")] <- "Miss."
titles[titles == "Mme."] <- "Mrs."
titles[titles %in% c("Jonkheer.", "Don.")] <- "Sir."
titles[titles %in% c("Col.", "Capt.", "Major.")] <- "Officer"
table(titles)

```
```{r}
# Make title a factor
data.combined$new.title <- as.factor(titles)

# Visualize new version of title
ggplot(data.combined[1:891,], aes(x = new.title, fill = Survived)) +
  geom_bar() +
  facet_wrap(~ Pclass) + 
  ggtitle("Surival Rates for new.title by pclass")

```


```{r}
# Collapse titles based on visual analysis
indexes <- which(data.combined$new.title == "Lady.")
data.combined$new.title[indexes] <- "Mrs."

indexes <- which(data.combined$new.title == "Dr." | 
                 data.combined$new.title == "Rev." |
                 data.combined$new.title == "Sir." |
                 data.combined$new.title == "Officer")
data.combined$new.title[indexes] <- "Mr."

```


```{r}
ggplot(data.combined[1:891,], aes(x = new.title, fill = Survived)) +
  geom_bar() +
  facet_wrap(~ Pclass) +
  ggtitle("Surival Rates for Collapsed new.title by pclass")

```


```{r}
# Grab features
features <- c("Pclass", "new.title", "family.size")
rpart.train.2 <- data.combined[1:891, features]

# Run CV and check out results
rpart.2.cv.1 <- rpart.cv(94622, rpart.train.2, rf.label, ctrl.3)
rpart.2.cv.1
```

```{r}
# Plot
prp(rpart.2.cv.1$finalModel, type = 0, extra = 1, under = TRUE)

```

```{r}
# Dive in on 1st class Mr."
indexes.first.mr <- which(data.combined$new.title == "Mr." & data.combined$Pclass == "1")
first.mr.df <- data.combined[indexes.first.mr, ]
summary(first.mr.df)
```

```{r}
# One female?
first.mr.df[first.mr.df$Sex == "female",]
```

```{r}
# Update new.title feature
indexes <- which(data.combined$new.title == "Mr." & 
                 data.combined$Sex == "female")
data.combined$new.title[indexes] <- "Mrs."
```


```{r}
#Any other gender slip ups?
length(which(data.combined$Sex == "female" & 
             (data.combined$new.title == "Master." |
              data.combined$new.title == "Mr.")))
```


```{r}

indexes.first.mr <- which(data.combined$new.title == "Mr." & data.combined$Pclass == "1")
first.mr.df <- data.combined[indexes.first.mr, ]

# Let's look at surviving 1st class "Mr."
summary(first.mr.df[first.mr.df$Survived == "1",])

```


```{r}

# Take a look at some of the high fares
indexes <- which(data.combined$Ticket == "PC 17755" |
                 data.combined$Ticket == "PC 17611" |
                 data.combined$Ticket == "113760")


```


```{r}
# Visualize survival rates for 1st class "Mr." by fare
ggplot(first.mr.df, aes(x = Fare, fill = Survived)) +
  geom_density(alpha = 0.5) +
  ggtitle("1st Class 'Mr.' Survival Rates by fare")

```


```{r}
# Engineer features based on all the passengers with the same ticket
ticket.party.size <- rep(0, nrow(data.combined))
avg.fare <- rep(0.0, nrow(data.combined))
tickets <- unique(data.combined$Ticket)
```

```{r}
for (i in 1:length(tickets)) {
  current.ticket <- tickets[i]
  party.indexes <- which(data.combined$Ticket == current.ticket)
  current.avg.fare <- data.combined[party.indexes[1], "Fare"] / length(party.indexes)
  
  for (k in 1:length(party.indexes)) {
    ticket.party.size[party.indexes[k]] <- length(party.indexes)
    avg.fare[party.indexes[k]] <- current.avg.fare
  }
}

```


```{r}
data.combined$ticket.party.size <- ticket.party.size
data.combined$avg.fare <- avg.fare
```


```{r}
data.combined$ticket.party.size <- ticket.party.size
data.combined$avg.fare <- avg.fare

# Refresh 1st class "Mr." dataframe
first.mr.df <- data.combined[indexes.first.mr, ]
summary(first.mr.df)

```

```{r}
# Visualize new features
ggplot(first.mr.df[first.mr.df$Survived != "None",], aes(x = ticket.party.size, fill = Survived)) +
  geom_density(alpha = 0.5) +
  ggtitle("Survival Rates 1st Class 'Mr.' by ticket.party.size")


```
```{r}
ggplot(first.mr.df[first.mr.df$Survived != "None",], aes(x = avg.fare, fill = Survived)) +
  geom_density(alpha = 0.5) +
  ggtitle("Survival Rates 1st Class 'Mr.' by avg.fare")


```

```{r}
# OK, let's see if our feature engineering has made any difference
features <- c("Pclass", "new.title", "family.size", "ticket.party.size", "avg.fare")
rpart.train.3 <- data.combined[1:891, features]

```


```{r}
# Run CV and check out results
rpart.3.cv.1 <- rpart.cv(94622, rpart.train.3, rf.label, ctrl.3)
rpart.3.cv.1
```

```{r}
# Plot
prp(rpart.3.cv.1$finalModel, type = 0, extra = 1, under = TRUE)

```

```{r}
#Subset our test records and features
test.submit.df <- data.combined[892:1309, features]

# Make predictions
rpart.3.preds <- predict(rpart.3.cv.1$finalModel, test.submit.df, type = "class")
table(rpart.3.preds)

```

```{r}
# Write out a CSV file for submission to Kaggle
submit.df <- data.frame(PassengerId = rep(892:1309), Survived = rpart.3.preds)

write.csv(submit.df, file = "RPART.csv", row.names = FALSE)

```

```{r}
#Random forest 

features <- c("Pclass", "new.title", "ticket.party.size", "avg.fare")
rf.train.temp <- data.combined[1:891, features]

set.seed(1234)
rf.temp <- randomForest(x = rf.train.temp, y = rf.label, ntree = 1000)
rf.temp


test.submit.df <- data.combined[892:1309, features]

# Make predictions
rf.preds <- predict(rf.temp, test.submit.df)
table(rf.preds)

```

```{r}
# Write out a CSV file for submission to Kaggle
submit.df <- data.frame(PassengerId = rep(892:1309), Survived = rf.preds)

write.csv(submit.df, file = "RF_SUB.csv", row.names = FALSE)

```

